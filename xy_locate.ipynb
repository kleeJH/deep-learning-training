{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Model to predict the XY coordinate of the staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 # Extract images from video\n",
    "import tensorflow as tf # Tensorflow stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (20, 720, 960, 3)  y: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/xy_locate/train.csv')\n",
    "df.head()\n",
    "X_img_name = df['img_number']\n",
    "X = []\n",
    "y = df[['x_position', 'y_position']]\n",
    "\n",
    "for i in range(len(X_img_name)):\n",
    "    im = cv2.imread('./data/xy_locate/{}'.format(str(X_img_name[i])))\n",
    "    X.append(im)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"x: \" + str(X.shape) + \"  y: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize, normalising X and preprocess for ResNet50\n",
    "X = X.astype('float32')\n",
    "X /= 255\n",
    "\n",
    "X = tf.image.resize(images=X, size=[240, 320])\n",
    "X = tf.keras.applications.resnet50.preprocess_input(X)\n",
    "X = X.numpy()\n",
    "\n",
    "# Split x and y into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 240, 320, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 246, 326, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 120, 160, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 120, 160, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 120, 160, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 122, 162, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 60, 80, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 60, 80, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 60, 80, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 60, 80, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 60, 80, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 60, 80, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 60, 80, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 60, 80, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 60, 80, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 60, 80, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 60, 80, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 60, 80, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 60, 80, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 60, 80, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 60, 80, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 60, 80, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 60, 80, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 60, 80, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 60, 80, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 60, 80, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 60, 80, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 60, 80, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 60, 80, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 60, 80, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 60, 80, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 60, 80, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 60, 80, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 60, 80, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 60, 80, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 60, 80, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 60, 80, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 60, 80, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 60, 80, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 30, 40, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 30, 40, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 30, 40, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 30, 40, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 30, 40, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 30, 40, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 30, 40, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 30, 40, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 30, 40, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 30, 40, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 30, 40, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 30, 40, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 30, 40, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 30, 40, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 30, 40, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 30, 40, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 30, 40, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 30, 40, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 30, 40, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 30, 40, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 30, 40, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 30, 40, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 30, 40, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 30, 40, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 30, 40, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 30, 40, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 30, 40, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 30, 40, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 15, 20, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 15, 20, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 15, 20, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 15, 20, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 15, 20, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 15, 20, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 15, 20, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 15, 20, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 15, 20, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 15, 20, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 15, 20, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 15, 20, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 15, 20, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 15, 20, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 15, 20, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 15, 20, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 15, 20, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 15, 20, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 15, 20, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 15, 20, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 15, 20, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 15, 20, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 15, 20, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 15, 20, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 15, 20, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 15, 20, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 15, 20, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 15, 20, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 15, 20, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 15, 20, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 15, 20, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 15, 20, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 15, 20, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 15, 20, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 8, 10, 512)   524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 8, 10, 512)  2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 8, 10, 512)  0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 8, 10, 512)   2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 8, 10, 512)  2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 8, 10, 512)  0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 8, 10, 2048)  2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 8, 10, 2048)  1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 8, 10, 2048)  8192       ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 8, 10, 2048)  8192       ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 8, 10, 2048)  0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 8, 10, 2048)  0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 8, 10, 512)   1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 8, 10, 512)  2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 8, 10, 512)  0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 8, 10, 512)   2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 8, 10, 512)  2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 8, 10, 512)  0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 8, 10, 2048)  1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 8, 10, 2048)  8192       ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 8, 10, 2048)  0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 8, 10, 2048)  0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 8, 10, 512)   1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 8, 10, 512)  2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 8, 10, 512)  0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 8, 10, 512)   2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 8, 10, 512)  2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 8, 10, 512)  0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 8, 10, 2048)  1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 8, 10, 2048)  8192       ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 8, 10, 2048)  0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 8, 10, 2048)  0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 163840)       0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          20971648    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            66          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 44,569,762\n",
      "Trainable params: 20,982,050\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# USE WEIGHTS FROM PREDICTION MODEL\n",
    "# base_model = tf.keras.applications.ResNet50(input_shape=(240, 320, 3), include_top=False, weights='imagenet')\n",
    "loaded_model = tf.keras.models.load_model(\"./model/prediction/prediction_model_2\")\n",
    "\n",
    "# Freeze trainable layers except for last few layers\n",
    "loaded_model.trainable = False\n",
    "\n",
    "output = loaded_model.layers[-6].output\n",
    "output = tf.keras.layers.Flatten() (output)\n",
    "\n",
    "# Add new FC Layers to the output that can predict the XY coordinate and prediction\n",
    "output = tf.keras.layers.Dense(128, activation=\"relu\") (output)\n",
    "output = tf.keras.layers.Dense(64, activation=\"relu\") (output)\n",
    "output = tf.keras.layers.Dense(32, activation=\"relu\") (output)\n",
    "output = tf.keras.layers.Dense(2, activation=None) (output) # no need activation function, 2 units for XY coordinates of the tag\n",
    "\n",
    "model = tf.keras.models.Model(inputs=loaded_model.input, outputs=output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/4 [======>.......................] - ETA: 6s - loss: 43668.1641 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 17s 5s/step - loss: 44829.6641 - accuracy: 0.5000 - val_loss: 20975.0234 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 42243.8398 - accuracy: 0.5000 - val_loss: 26835.5039 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 43412.8906 - accuracy: 0.5000 - val_loss: 23511.8438 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 42202.1953 - accuracy: 0.5000 - val_loss: 19869.1406 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 40477.4805 - accuracy: 0.5000 - val_loss: 20942.8242 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 41569.1016 - accuracy: 0.5000 - val_loss: 23842.3281 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 40945.4531 - accuracy: 0.5000 - val_loss: 20931.2402 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 40293.3203 - accuracy: 0.5000 - val_loss: 20423.7305 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 39264.1953 - accuracy: 0.5000 - val_loss: 20530.4141 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 39310.6836 - accuracy: 0.5000 - val_loss: 20422.6562 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 39255.3672 - accuracy: 0.5000 - val_loss: 21806.2852 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 38356.9180 - accuracy: 0.5000 - val_loss: 19671.5156 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 38080.6875 - accuracy: 0.5000 - val_loss: 20054.5586 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 38102.6523 - accuracy: 0.5000 - val_loss: 18865.8379 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 39240.5078 - accuracy: 0.5000 - val_loss: 22022.3906 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 37214.8945 - accuracy: 0.5000 - val_loss: 20322.5098 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 39261.9648 - accuracy: 0.5000 - val_loss: 19441.1289 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 36975.8867 - accuracy: 0.5000 - val_loss: 20502.9727 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 36095.7852 - accuracy: 0.5000 - val_loss: 21729.8398 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 36680.9219 - accuracy: 0.5000 - val_loss: 20151.8184 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 35924.4297 - accuracy: 0.5000 - val_loss: 17399.7305 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 34730.0508 - accuracy: 0.5000 - val_loss: 18351.5957 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 34979.9766 - accuracy: 0.5000 - val_loss: 21761.1387 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 34752.0703 - accuracy: 0.5000 - val_loss: 18466.7422 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 33486.5703 - accuracy: 0.5000 - val_loss: 17479.2344 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 32912.9023 - accuracy: 0.5000 - val_loss: 19284.2812 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 33021.2109 - accuracy: 0.5000 - val_loss: 18774.1426 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 32555.3770 - accuracy: 0.5000 - val_loss: 18307.7383 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 32039.4453 - accuracy: 0.5000 - val_loss: 17573.0977 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 31042.2656 - accuracy: 0.5000 - val_loss: 19343.2031 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 29705.7539 - accuracy: 0.5000 - val_loss: 17650.1777 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 31809.7656 - accuracy: 0.5000 - val_loss: 16333.6729 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 27895.1816 - accuracy: 0.5000 - val_loss: 16186.7021 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 27321.5371 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 5s/step - loss: 30005.4043 - accuracy: 0.6250 - val_loss: 21530.9727 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 30339.6523 - accuracy: 0.5625 - val_loss: 19668.8652 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 29811.5723 - accuracy: 0.5000 - val_loss: 14027.9453 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 25522.9258 - accuracy: 0.5000 - val_loss: 16084.5371 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 24831.5273 - accuracy: 0.5000 - val_loss: 20487.2852 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 24505.8945 - accuracy: 0.6250 - val_loss: 16163.7178 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 22615.1270 - accuracy: 0.6250 - val_loss: 13924.9521 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 19441.2461 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 5s/step - loss: 22063.2930 - accuracy: 0.7500 - val_loss: 14539.7305 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 21953.0391 - accuracy: 0.5625 - val_loss: 15022.2256 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 19164.4844 - accuracy: 0.6875 - val_loss: 13381.0020 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 27743.7734 - accuracy: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 5s/step - loss: 21996.7266 - accuracy: 0.9375 - val_loss: 14641.8770 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 17087.4141 - accuracy: 0.6875 - val_loss: 20914.6348 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 18662.9434 - accuracy: 0.5625 - val_loss: 10316.7842 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 15250.1758 - accuracy: 0.8750 - val_loss: 13510.9814 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 15640.3271 - accuracy: 0.8750 - val_loss: 14482.3105 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 15763.0449 - accuracy: 0.8125 - val_loss: 9498.5547 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 16470.5059 - accuracy: 0.6250 - val_loss: 19182.3945 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 17841.3711 - accuracy: 0.8750 - val_loss: 10206.9678 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 17688.7422 - accuracy: 0.6875 - val_loss: 23698.5234 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 9561.4561 - accuracy: 0.8125 - val_loss: 10512.0967 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 9971.4326 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/xy_locate\\xy_locate_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 5s/step - loss: 13673.1924 - accuracy: 1.0000 - val_loss: 20351.0234 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 13302.6240 - accuracy: 0.8125 - val_loss: 15053.9668 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 6720.2261 - accuracy: 0.9375 - val_loss: 7568.9390 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8432.9756 - accuracy: 1.0000 - val_loss: 15068.2441 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 7612.2100 - accuracy: 0.8750 - val_loss: 14811.3447 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8335.8242 - accuracy: 1.0000 - val_loss: 9731.9141 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8875.0117 - accuracy: 0.8125 - val_loss: 13972.1836 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8549.1055 - accuracy: 1.0000 - val_loss: 8564.0098 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8109.3408 - accuracy: 0.9375 - val_loss: 20357.1250 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 7116.3843 - accuracy: 0.9375 - val_loss: 9290.9092 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 5902.6963 - accuracy: 0.9375 - val_loss: 13925.2715 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4563.7046 - accuracy: 0.9375 - val_loss: 8648.2285 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4171.7515 - accuracy: 1.0000 - val_loss: 12093.3867 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4964.6035 - accuracy: 0.8750 - val_loss: 10527.8291 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4332.0239 - accuracy: 1.0000 - val_loss: 9006.6582 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4184.6353 - accuracy: 1.0000 - val_loss: 12953.3496 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4294.2275 - accuracy: 0.9375 - val_loss: 10163.4609 - val_accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4047.6128 - accuracy: 0.8750 - val_loss: 11779.7246 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3490.8823 - accuracy: 1.0000 - val_loss: 8691.7520 - val_accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3245.5261 - accuracy: 1.0000 - val_loss: 13650.2734 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3484.3550 - accuracy: 1.0000 - val_loss: 9568.4297 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2989.3599 - accuracy: 1.0000 - val_loss: 12185.8262 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3405.7969 - accuracy: 1.0000 - val_loss: 10679.7246 - val_accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3152.9292 - accuracy: 0.9375 - val_loss: 10327.2490 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2615.4036 - accuracy: 1.0000 - val_loss: 10185.2549 - val_accuracy: 0.7500\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3265.5151 - accuracy: 1.0000 - val_loss: 13016.8789 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2275.7646 - accuracy: 1.0000 - val_loss: 8512.8887 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2788.4158 - accuracy: 1.0000 - val_loss: 9622.4453 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2740.0869 - accuracy: 1.0000 - val_loss: 12188.3174 - val_accuracy: 0.7500\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2498.2881 - accuracy: 1.0000 - val_loss: 9271.4717 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2229.9014 - accuracy: 1.0000 - val_loss: 9317.6240 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2114.6621 - accuracy: 1.0000 - val_loss: 10908.5010 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2037.5522 - accuracy: 1.0000 - val_loss: 9341.6172 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2257.4529 - accuracy: 1.0000 - val_loss: 10669.3037 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1989.1021 - accuracy: 1.0000 - val_loss: 9771.9258 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2003.2841 - accuracy: 1.0000 - val_loss: 11455.7637 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1916.1388 - accuracy: 0.9375 - val_loss: 8951.0215 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1890.1479 - accuracy: 1.0000 - val_loss: 11701.4336 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1842.1438 - accuracy: 1.0000 - val_loss: 10291.1924 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1528.5618 - accuracy: 1.0000 - val_loss: 9034.7246 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1693.2805 - accuracy: 1.0000 - val_loss: 10407.2617 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1728.7932 - accuracy: 1.0000 - val_loss: 9631.4268 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1482.6594 - accuracy: 1.0000 - val_loss: 9902.5996 - val_accuracy: 0.7500\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1366.6185 - accuracy: 1.0000 - val_loss: 10643.2715 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1371.4700 - accuracy: 1.0000 - val_loss: 9373.8008 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1623.3323 - accuracy: 1.0000 - val_loss: 11298.5225 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1473.8234 - accuracy: 1.0000 - val_loss: 8802.7344 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1145.6824 - accuracy: 1.0000 - val_loss: 11856.9199 - val_accuracy: 0.7500\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1370.8699 - accuracy: 1.0000 - val_loss: 9139.8896 - val_accuracy: 0.7500\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1736.4720 - accuracy: 1.0000 - val_loss: 10168.1934 - val_accuracy: 0.7500\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2047.0625 - accuracy: 1.0000 - val_loss: 10951.7988 - val_accuracy: 0.7500\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1837.9882 - accuracy: 1.0000 - val_loss: 9665.4961 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1531.1548 - accuracy: 1.0000 - val_loss: 10687.7959 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1238.6667 - accuracy: 1.0000 - val_loss: 10117.8340 - val_accuracy: 0.7500\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1009.8867 - accuracy: 1.0000 - val_loss: 8819.9902 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1049.1323 - accuracy: 1.0000 - val_loss: 10415.1309 - val_accuracy: 0.7500\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 825.8065 - accuracy: 1.0000 - val_loss: 10514.9766 - val_accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 993.0975 - accuracy: 1.0000 - val_loss: 9080.8232 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1024.4177 - accuracy: 1.0000 - val_loss: 10394.3203 - val_accuracy: 0.7500\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 972.4370 - accuracy: 1.0000 - val_loss: 8641.9141 - val_accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 715.3394 - accuracy: 1.0000 - val_loss: 11854.0391 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 710.8676 - accuracy: 1.0000 - val_loss: 7852.9009 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 806.3461 - accuracy: 1.0000 - val_loss: 10880.8662 - val_accuracy: 0.7500\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 893.3972 - accuracy: 1.0000 - val_loss: 8561.4336 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 883.1995 - accuracy: 1.0000 - val_loss: 11072.8545 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1038.7625 - accuracy: 1.0000 - val_loss: 9565.2158 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 992.0367 - accuracy: 1.0000 - val_loss: 9206.9160 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 768.9749 - accuracy: 1.0000 - val_loss: 10996.5430 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 613.3690 - accuracy: 1.0000 - val_loss: 7599.0664 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 558.1752 - accuracy: 1.0000 - val_loss: 12045.0195 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 732.0740 - accuracy: 1.0000 - val_loss: 8562.0078 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 578.0848 - accuracy: 1.0000 - val_loss: 10155.4521 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 467.8580 - accuracy: 1.0000 - val_loss: 9901.4961 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 338.4359 - accuracy: 1.0000 - val_loss: 9310.1621 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 464.0179 - accuracy: 1.0000 - val_loss: 9730.5537 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 371.3575 - accuracy: 1.0000 - val_loss: 9658.6299 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 414.3206 - accuracy: 1.0000 - val_loss: 9511.1816 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 462.7677 - accuracy: 1.0000 - val_loss: 9447.8877 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 353.1487 - accuracy: 1.0000 - val_loss: 9927.2354 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 406.7255 - accuracy: 1.0000 - val_loss: 9299.1592 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 316.7096 - accuracy: 1.0000 - val_loss: 9535.0605 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 404.5403 - accuracy: 1.0000 - val_loss: 9653.0801 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 261.9710 - accuracy: 1.0000 - val_loss: 9964.6270 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 343.3629 - accuracy: 1.0000 - val_loss: 9259.2656 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 262.7685 - accuracy: 1.0000 - val_loss: 9817.5107 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 233.9575 - accuracy: 1.0000 - val_loss: 8956.0742 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 292.9655 - accuracy: 1.0000 - val_loss: 10114.8555 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 292.0807 - accuracy: 1.0000 - val_loss: 9216.5195 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 290.4909 - accuracy: 1.0000 - val_loss: 10490.9082 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 215.9559 - accuracy: 1.0000 - val_loss: 9386.1904 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 255.3529 - accuracy: 1.0000 - val_loss: 10149.2012 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 226.0762 - accuracy: 1.0000 - val_loss: 8877.3770 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 241.7479 - accuracy: 1.0000 - val_loss: 9749.1377 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 218.1322 - accuracy: 1.0000 - val_loss: 8449.6768 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 255.3134 - accuracy: 1.0000 - val_loss: 10381.6387 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 304.2559 - accuracy: 1.0000 - val_loss: 8776.7217 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 270.4172 - accuracy: 1.0000 - val_loss: 10512.0898 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 278.8457 - accuracy: 1.0000 - val_loss: 8680.7451 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 252.8136 - accuracy: 1.0000 - val_loss: 9581.8545 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 226.6673 - accuracy: 1.0000 - val_loss: 9914.8379 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 168.2842 - accuracy: 1.0000 - val_loss: 8780.9014 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 247.2485 - accuracy: 1.0000 - val_loss: 10088.7871 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 179.3867 - accuracy: 1.0000 - val_loss: 8783.1406 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 192.1312 - accuracy: 1.0000 - val_loss: 9663.3438 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 255.9700 - accuracy: 1.0000 - val_loss: 9647.0771 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 297.8165 - accuracy: 1.0000 - val_loss: 8911.0674 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 242.8386 - accuracy: 1.0000 - val_loss: 10041.2988 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 221.1739 - accuracy: 1.0000 - val_loss: 8511.7012 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 215.1510 - accuracy: 1.0000 - val_loss: 10059.1787 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 159.3578 - accuracy: 1.0000 - val_loss: 9265.5977 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 161.8558 - accuracy: 1.0000 - val_loss: 9819.4111 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 139.9387 - accuracy: 1.0000 - val_loss: 8928.9902 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 101.6606 - accuracy: 1.0000 - val_loss: 9536.6436 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.3370 - accuracy: 1.0000 - val_loss: 8875.1348 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 114.7790 - accuracy: 1.0000 - val_loss: 9509.0693 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 120.3932 - accuracy: 1.0000 - val_loss: 9150.6680 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 127.7149 - accuracy: 1.0000 - val_loss: 9172.9600 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 117.6469 - accuracy: 1.0000 - val_loss: 9574.1699 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 81.3610 - accuracy: 1.0000 - val_loss: 9071.5312 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 78.8125 - accuracy: 1.0000 - val_loss: 9506.8369 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 78.2174 - accuracy: 1.0000 - val_loss: 9270.4512 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 78.8358 - accuracy: 1.0000 - val_loss: 9532.0430 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 71.2377 - accuracy: 1.0000 - val_loss: 9531.9258 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 85.8261 - accuracy: 1.0000 - val_loss: 9475.1895 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 70.0760 - accuracy: 1.0000 - val_loss: 9218.5703 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 72.5319 - accuracy: 1.0000 - val_loss: 9170.7207 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 57.5099 - accuracy: 1.0000 - val_loss: 9550.5635 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 58.7098 - accuracy: 1.0000 - val_loss: 9154.1797 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 62.3996 - accuracy: 1.0000 - val_loss: 9540.8809 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 64.3262 - accuracy: 1.0000 - val_loss: 8866.3867 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 72.4356 - accuracy: 1.0000 - val_loss: 9826.1953 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 75.6467 - accuracy: 1.0000 - val_loss: 8896.0010 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 89.7251 - accuracy: 1.0000 - val_loss: 10103.8652 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 85.0726 - accuracy: 1.0000 - val_loss: 8888.9707 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 92.8875 - accuracy: 1.0000 - val_loss: 9895.0098 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 74.1634 - accuracy: 1.0000 - val_loss: 9002.6064 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 67.9777 - accuracy: 1.0000 - val_loss: 9375.3154 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 60.7159 - accuracy: 1.0000 - val_loss: 8978.8994 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 60.7294 - accuracy: 1.0000 - val_loss: 9077.7295 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 75.2812 - accuracy: 1.0000 - val_loss: 8967.8584 - val_accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 69.2487 - accuracy: 1.0000 - val_loss: 9519.1699 - val_accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 62.2540 - accuracy: 1.0000 - val_loss: 8675.8740 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 68.1383 - accuracy: 1.0000 - val_loss: 9728.0195 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 56.1247 - accuracy: 1.0000 - val_loss: 8902.9941 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 59.0956 - accuracy: 1.0000 - val_loss: 9711.4551 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 48.5702 - accuracy: 1.0000 - val_loss: 8857.8613 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 48.9522 - accuracy: 1.0000 - val_loss: 9251.3545 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# MODEL PARAMETERS\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "OPTIMIZER = tf.optimizers.Adam()\n",
    "LOSS_FUNC = tf.keras.losses.mean_squared_error # want to look at the error between actual and prediction\n",
    "\n",
    "CALLBACKS = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=\"./model/xy_locate/xy_locate_model\", monitor='accuracy', mode='max', verbose=False, save_best_only=True)\n",
    "        ]\n",
    "\n",
    "# Initialize optimizer, compile and start fine tuning the model\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, callbacks=CALLBACKS, epochs=EPOCHS, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"./model/xy_locate/xy_locate_model_2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
